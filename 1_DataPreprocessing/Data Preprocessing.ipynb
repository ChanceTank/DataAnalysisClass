{"cells":[{"cell_type":"markdown","metadata":{"id":"mkdLPRSe6ALU"},"source":["# Authors\n","\\<Adiba Akter\\>\n","\\<Richard\\>\n","\\<John\\>\n","\\<Tyson\\>"]},{"cell_type":"markdown","metadata":{"id":"6HVll9inTTN0"},"source":["# Data Domain\n","\n","The data we are using is on exoplanets from the NASA Exoplanet Archive. It includes various attributes of known exoplanets, such as their names, host stars, orbital characteristics, and physical parameters like mass and radius. The table is designed for researchers and enthusiasts to analyze and compare the properties of these distant worlds.\n","\n","The first 88 rows of the csv file contain full descriptions of the columns shorthand names. So to make the file readable for panda, those rows have to be removed."]},{"cell_type":"markdown","metadata":{"id":"nqdFLZRR6NSM"},"source":["# Importing Libraries\n","\n","The following cell imports all libraries that will be used for this notebook."]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":1186,"status":"ok","timestamp":1727298486070,"user":{"displayName":"Richard Varela","userId":"15051946026457836607"},"user_tz":420},"id":"A-EUxTFU6V6I"},"outputs":[],"source":["import numpy as np\n","import scipy as sp\n","import pandas as pd\n","# IMPORTANT: Allows this notebook to get data if on Colab.\n","# Comment out if running locally.\n","#from google.colab import drive"]},{"cell_type":"markdown","metadata":{"id":"Bi5-rfiu6bM7"},"source":["# Data Preprocessing"]},{"cell_type":"markdown","metadata":{"id":"plQfwPol6eyw"},"source":["# Gathering the Data\n","\n","The following code cell will import the data from the CSV file and put it in a Pandas `DataFrame`.\n","\n","Here, `pd.read_csv` function is used from the Pandos library which will read the CSV file the data is currently in. The parameter `comment` tells the function that there are comments in the CSV file and will handle them appropriately to prevent errors and garbage from being put into the `DataFrame` `df_data`."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":970},"executionInfo":{"elapsed":2957,"status":"ok","timestamp":1727298516800,"user":{"displayName":"Richard Varela","userId":"15051946026457836607"},"user_tz":420},"id":"ug36AO3B6rsp","outputId":"c5b06984-b8b4-483b-c71b-47bf47d6fae8"},"outputs":[],"source":["# Path to the file. If on Colab, use the appropriate Colab package to import\n","#  the data.\n","path = \"/PSCompPars_2024.09.17_17.11.11.csv\"\n","\n","# IMPORTANT: If running on Google Colab, uncomment this line and use instead.\n","#  You will need to enable permissions on your account to use.\n","# If you are doing this locally, please use the file path above instead.\n","#drive.mount('/content/drive')\n","#path = \"/content/drive/My Drive/School/SacStateClasses/CSC177/CSC177_GroupFolder/1_DataPreprocessing/PSCompPars_2024.09.17_17.11.11.csv\"\n","\n","path = \"./ORI_PSCompPars_2024.09.17_17.11.11.csv\" #from Adiba, helpful when you download in zip from google drive, if working on collab, comment this line and use other path above\n","\n","df_data = pd.read_csv(path, comment='#', na_values=['', np.nan])\n","\n","\n","print(\"Display information about the DataFrame:\")\n","print(df_data.dtypes)\n","print(\"\\nShow contents of the data:\")\n","df_data"]},{"cell_type":"markdown","metadata":{"id":"c8jV1COM9LXt"},"source":["# Preprocessing the Data"]},{"cell_type":"markdown","metadata":{"id":"Zfttc2tS9Nix"},"source":["## Remove Duplicate Data\n","\n","The first operation will be to remove any possible duplicate data from the `DataFrame`."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":476},"executionInfo":{"elapsed":165,"status":"ok","timestamp":1727299241245,"user":{"displayName":"Richard Varela","userId":"15051946026457836607"},"user_tz":420},"id":"Ko_0VvZr9dN6","outputId":"6216ea92-b3c3-4fc2-e96d-d7426bdd70f9"},"outputs":[],"source":["# Code for duplicate data.\n","dups = df_data.duplicated()\n","print(f\"Number of duplicate rows = {dups.sum()}\")\n","dups\n","# Uncomment this line if the data has any duplicats\n","#df_data = df_data.drop_duplicates()"]},{"cell_type":"markdown","metadata":{"id":"mJRm_t2TDtaC"},"source":["The following cell will remove any duplicates using the `duplicated` method of the `DataFrame`."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":476},"executionInfo":{"elapsed":195,"status":"ok","timestamp":1727299293361,"user":{"displayName":"Richard Varela","userId":"15051946026457836607"},"user_tz":420},"id":"vMprme1UD292","outputId":"0f1ad725-0827-4a3c-8869-e5b1bf1e3284"},"outputs":[],"source":["df_data.drop_duplicates(inplace=True)\n","dups = df_data.duplicated()\n","print(f\"Duplicates: {dups.sum()}\")\n","dups"]},{"cell_type":"markdown","metadata":{"id":"lPqG3ZPx9egZ"},"source":["## Fill In Missing Values\n","\n","The next operation is to fill in any possible missing data values. Several columns where the uncertainty is null, we replace them with the mean uncertainty. There are a few steps that must be taken however:\n","\n","1. Replace any missing data points with `np.nan`.\n","2. Replace `np.nan` with the *mean* of that attribute."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":687},"executionInfo":{"elapsed":322,"status":"ok","timestamp":1727200714316,"user":{"displayName":"John Simon","userId":"06194638627835408677"},"user_tz":420},"id":"vQNSlIL69q-T","outputId":"7afc6315-6e31-4593-d94b-236ead3df1e6"},"outputs":[],"source":["# This will go through the entire DataFrame and replace any empty attributes\n","#  with NaN using np.nan\n","df_data = df_data.replace('', np.nan)\n","df_data\n"]},{"cell_type":"markdown","metadata":{"id":"cRnOVdki-J9O"},"source":["After replacing missing attribute values with NaN, next is to replace those attribute values the mean for each feature. This is done by using the `mean` and `fillna` methods of the `df_data` object."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":704},"executionInfo":{"elapsed":179,"status":"ok","timestamp":1727299323682,"user":{"displayName":"Richard Varela","userId":"15051946026457836607"},"user_tz":420},"id":"tqu1RMu1-Qzd","outputId":"b3af17d1-caee-4f78-e6bb-178c5e166478"},"outputs":[],"source":["sr_mean_vals = df_data.mean(numeric_only=True) # Series that contains the mean\n","df_data.fillna(sr_mean_vals, inplace=True)\n","print(f\"df_data shape: {df_data.shape}\")\n","df_data"]},{"cell_type":"markdown","metadata":{},"source":["## Task 3: Data Transformation\n","In this task, we will be transforming the data by applying the following techniques:\n","\n","1. **Encoding categorical variables**: Categorical features need to be transformed into numerical values. We use one-hot encoding for this task to handle categories in a way that machine learning algorithms can process.\n","\n","2. **Normalization**: Numerical data is normalized using `StandardScaler()` to ensure that all features are on a similar scale, which is particularly important for algorithms sensitive to feature scaling.\n","\n","3. **Handling Outliers**: We identify and remove outliers using the Interquartile Range (IQR) method. This helps to ensure that extreme values do not unduly influence the modelâ€™s performance.\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["## Step 1: Encoding Categorical Variables"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Task 3: Encoding Categorical Variables\n","# The categorical columns are encoded using LabelEncoder\n","\n","from sklearn.preprocessing import LabelEncoder\n","\n","# List of categorical columns to encode\n","categorical_columns = ['discoverymethod', 'disc_facility', 'pl_name', 'hostname']\n","\n","# Encoding each categorical column using LabelEncoder\n","le = LabelEncoder()\n","for col in categorical_columns:\n","    df_data[col] = le.fit_transform(df_data[col].astype(str))\n","\n","# Display the first few rows of the encoded data\n","print(\"Encoded categorical data:\")\n","df_data[categorical_columns].head()"]},{"cell_type":"markdown","metadata":{},"source":["## Step 2: Normalizing Numerical Features"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Task 3: Normalizing Numerical Features\n","# Using StandardScaler to normalize the numerical columns\n","\n","from sklearn.preprocessing import StandardScaler\n","\n","# Selecting numerical columns for scaling\n","numerical_columns = df_data.select_dtypes(include=['float64', 'int64']).columns\n","\n","# Initializing the StandardScaler\n","scaler = StandardScaler()\n","\n","# Fitting the scaler to the numerical data and transforming it\n","df_data[numerical_columns] = scaler.fit_transform(df_data[numerical_columns])\n","\n","# Display the first few rows of the normalized data\n","print(\"Normalized data:\")\n","df_data[numerical_columns].head()\n"]},{"cell_type":"markdown","metadata":{},"source":["## Step 3: Handling Outliers with the IQR Method"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Task 3: Handling Outliers using the Interquartile Range (IQR)\n","# We detect outliers and filter them out\n","\n","# Calculating Q1 (25th percentile) and Q3 (75th percentile)\n","Q1 = df_data[numerical_columns].quantile(0.25)\n","Q3 = df_data[numerical_columns].quantile(0.75)\n","\n","# Calculating the Interquartile Range (IQR)\n","IQR = Q3 - Q1\n","\n","# Defining lower and upper bounds to identify outliers\n","lower_bound = Q1 - 1.5 * IQR\n","upper_bound = Q3 + 1.5 * IQR\n","\n","# Removing rows where any numerical column has outliers\n","df_data_cleaned = df_data[~((df_data[numerical_columns] < lower_bound) | \n","                            (df_data[numerical_columns] > upper_bound)).any(axis=1)]\n","\n","# Display the shape and a few rows of the cleaned dataset\n","print(f\"Data after handling outliers, original shape: {df_data.shape}, cleaned shape: {df_data_cleaned.shape}\")\n","df_data_cleaned.head()\n"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.18"}},"nbformat":4,"nbformat_minor":0}
